{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3f7abb-2f84-453b-be84-81df866728d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp.var.rate      0\n",
      "cons.price.idx    0\n",
      "cons.conf.idx     0\n",
      "euribor3m         0\n",
      "nr.employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "First 5 rows after preprocessing:\n",
      "             age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "25611  0.863739 -0.120196  0.522981  0.196584 -0.350127     -0.114858   \n",
      "26010 -0.289722 -0.216732 -0.203688  0.196584  1.653813     -0.114858   \n",
      "40194  3.651268  3.436173 -0.567023  0.196584 -0.350127     -1.133161   \n",
      "297   -0.385843 -0.533368 -0.203688  0.196584 -0.350127      0.648868   \n",
      "36344  1.824956  0.424264 -0.203688  0.196584 -0.350127     -1.896888   \n",
      "\n",
      "       cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month_may  \\\n",
      "25611       -0.648967      -0.322269   0.288964     0.398990  ...      False   \n",
      "26010       -0.648967      -0.322269   0.288964     0.398990  ...      False   \n",
      "40194        1.103451       0.045048  -1.583296    -2.420139  ...      False   \n",
      "297          0.721890       0.887717   0.713535     0.332723  ...       True   \n",
      "36344       -1.058152      -0.062987  -1.357472    -1.252175  ...      False   \n",
      "\n",
      "       month_nov  month_oct  month_sep  day_of_week_mon  day_of_week_thu  \\\n",
      "25611       True      False      False            False            False   \n",
      "26010       True      False      False            False            False   \n",
      "40194      False      False      False             True            False   \n",
      "297        False      False      False             True            False   \n",
      "36344      False      False      False            False            False   \n",
      "\n",
      "       day_of_week_tue  day_of_week_wed  poutcome_nonexistent  \\\n",
      "25611            False             True                  True   \n",
      "26010            False             True                 False   \n",
      "40194            False            False                  True   \n",
      "297              False            False                  True   \n",
      "36344             True            False                  True   \n",
      "\n",
      "       poutcome_success  \n",
      "25611             False  \n",
      "26010             False  \n",
      "40194             False  \n",
      "297               False  \n",
      "36344             False  \n",
      "\n",
      "[5 rows x 53 columns]\n",
      "Preprocessed data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\samia\\OneDrive\\Documents\\GitHub\\springboard\\Project Proposal\\bank+marketing\\bank-additional\\bank-additional\\bank-additional-full.csv\"\n",
    "\n",
    "# Check if the file exists and load the data\n",
    "if os.path.exists(file_path):\n",
    "    bank_additional_full = pd.read_csv(file_path, sep=';')  # Ensure correct separator\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# Step 1: Check if there are any missing values in the dataset\n",
    "print(bank_additional_full.isnull().sum())\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "bank_additional_full.fillna(bank_additional_full.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Step 3: Identify feature columns\n",
    "target_column = \"y\"  # Update if needed\n",
    "if target_column not in bank_additional_full.columns:\n",
    "    print(\"Error: Target column not found.\")\n",
    "    exit()\n",
    "\n",
    "X = bank_additional_full.drop(columns=[target_column])\n",
    "y = bank_additional_full[target_column].map({'yes': 1, 'no': 0})  # Convert target to binary\n",
    "\n",
    "# Step 4: Train-Test Split BEFORE transformations\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Step 5: Convert categorical columns to dummies separately\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_columns, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Ensure both train & test have the same dummy columns\n",
    "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0  # Add missing columns in test set\n",
    "\n",
    "X_test = X_test[X_train.columns]  # Reorder columns to match training set\n",
    "\n",
    "# Step 6: Standardize Numeric Features (Only on Train, then Apply to Test)\n",
    "numeric_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "if numeric_columns.empty:\n",
    "    print(\"Warning: No numeric columns found.\")\n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "    X_train.loc[:, numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n",
    "    X_test.loc[:, numeric_columns] = scaler.transform(X_test[numeric_columns])  # Apply same scaling\n",
    "\n",
    "# Step 7: Verify Data\n",
    "print(\"First 5 rows after preprocessing:\\n\", X_train.head())\n",
    "\n",
    "# Step 8: Save Preprocessed Data (Optional)\n",
    "X_train.to_csv(\"X_train_preprocessed.csv\", index=False)\n",
    "X_test.to_csv(\"X_test_preprocessed.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessed data saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346b214-6a5c-4b0b-a870-7e2d288bf8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
